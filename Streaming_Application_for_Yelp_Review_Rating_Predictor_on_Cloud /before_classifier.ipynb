{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "PySpark",
      "language": "python",
      "name": "pyspark"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "before-classifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2e73ba80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "outputId": "f7ce48ba-af20-4384-b781-8d362f9038e0"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as F\n",
        "import pyspark.sql.types as T\n",
        "from pyspark.ml.feature import Tokenizer, HashingTF, IDF\n",
        "from pyspark.ml.classification import DecisionTreeClassifier,NaiveBayes,LogisticRegression\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler"
      ],
      "id": "2e73ba80",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-07793d1d3aac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypes\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHashingTF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIDF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNaiveBayes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "741b53e5",
        "outputId": "14db7842-cd52-4705-869e-46b5cb1c205b"
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "id": "741b53e5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ba4ac19a"
      },
      "source": [
        "spark = SparkSession.builder \\\n",
        "    .appName(\"text_classification_trainer\") \\\n",
        "    .master(\"local\") \\\n",
        "    .getOrCreate()"
      ],
      "id": "ba4ac19a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d61c9f8f"
      },
      "source": [
        "df = spark.read.json(\"gs://finalprojectbdl2021/yelp_train.json\")"
      ],
      "id": "d61c9f8f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1a28a234",
        "outputId": "538cb5dd-0161-4e5a-c4b2-a7127a77e911"
      },
      "source": [
        "df.show(5)"
      ],
      "id": "1a28a234",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+----+-------------------+-----+--------------------+-----+--------------------+------+--------------------+\n",
            "|         business_id|cool|               date|funny|           review_id|stars|                text|useful|             user_id|\n",
            "+--------------------+----+-------------------+-----+--------------------+-----+--------------------+------+--------------------+\n",
            "|--FnvijzY20d1nk9H...|   0|2019-10-09 17:11:51|    0|ha9TgGOiBr1l7Mi9D...|  5.0|Great Mexican Foo...|     0|czIk4xBskNcWieyWI...|\n",
            "|--SrzpvFLwP_YFwB_...|   1|2011-02-28 21:07:48|    0|a5DGTpucUmVYT-lyP...|  4.0|Keung's is one of...|     1|HFItzRohDHZvcKDrM...|\n",
            "|--cZ6Hhc9F7VkKXxH...|   0|2008-08-24 16:35:22|    0|0sRfH3GTUXqqxtkKc...|  4.0|The food is great...|     1|DQIt5Uv87fdS54b2o...|\n",
            "|--cZ6Hhc9F7VkKXxH...|   0|2010-01-18 18:50:25|    0|bgA8LHJ8yQ6h0PrpO...|  4.0|Saw this restaura...|     2|NnMCDFCsaiJ3OgvzZ...|\n",
            "|--cZ6Hhc9F7VkKXxH...|   0|2011-02-16 13:57:00|    0|-Ud_XVfiL4CAF4fAe...|  5.0|Delicious rotisse...|     0|8q5mg9bWe4A6wWufl...|\n",
            "+--------------------+----+-------------------+-----+--------------------+-----+--------------------+------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "407dc8c7",
        "outputId": "de34ca70-b46a-45c1-9aff-97a69e306d77"
      },
      "source": [
        "df.printSchema()"
      ],
      "id": "407dc8c7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- business_id: string (nullable = true)\n",
            " |-- cool: long (nullable = true)\n",
            " |-- date: string (nullable = true)\n",
            " |-- funny: long (nullable = true)\n",
            " |-- review_id: string (nullable = true)\n",
            " |-- stars: double (nullable = true)\n",
            " |-- text: string (nullable = true)\n",
            " |-- useful: long (nullable = true)\n",
            " |-- user_id: string (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "570b7269"
      },
      "source": [
        "data = df.select('text', 'stars').dropna()"
      ],
      "id": "570b7269",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5988be97",
        "outputId": "77157d56-577b-42a9-e871-1002bcbb88e7"
      },
      "source": [
        "data.show(5)"
      ],
      "id": "5988be97",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+-----+\n",
            "|                text|stars|\n",
            "+--------------------+-----+\n",
            "|Great Mexican Foo...|  5.0|\n",
            "|Keung's is one of...|  4.0|\n",
            "|The food is great...|  4.0|\n",
            "|Saw this restaura...|  4.0|\n",
            "|Delicious rotisse...|  5.0|\n",
            "+--------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1e3aed7"
      },
      "source": [
        "regexTokenizer = RegexTokenizer(inputCol=\"text\", outputCol=\"words\", pattern=\"\\\\W\")\n",
        "add_stopwords = stopwords.words('english')\n",
        "stopwordsRemover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\").setStopWords(add_stopwords)\n",
        "countVectors = CountVectorizer(inputCol=\"filtered\", outputCol=\"features\", vocabSize=1000, minDF=5)\n",
        "#label_stringIdx = StringIndexer(inputCol = \"stars\", outputCol = \"label\")"
      ],
      "id": "a1e3aed7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBjYd3g1Ns_t"
      },
      "source": [
        ""
      ],
      "id": "uBjYd3g1Ns_t"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dc30d8e6"
      },
      "source": [
        "pipeline = Pipeline(stages=[regexTokenizer, stopwordsRemover, countVectors])"
      ],
      "id": "dc30d8e6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cd7eca4"
      },
      "source": [
        "pipelineFit = pipeline.fit(data)\n",
        "data = pipelineFit.transform(data)"
      ],
      "id": "6cd7eca4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b436d360"
      },
      "source": [
        "(trainingData, testData) = data.randomSplit([0.8, 0.2], seed = 0)"
      ],
      "id": "b436d360",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdb8ce01"
      },
      "source": [
        "# trainingData.count()"
      ],
      "id": "cdb8ce01",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccab9000",
        "outputId": "6c19a4d4-e579-4918-88ee-f9ded4b55f5b"
      },
      "source": [
        "data.show(10)"
      ],
      "id": "ccab9000",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+-----+--------------------+--------------------+--------------------+-----+\n",
            "|                text|stars|               words|            filtered|            features|label|\n",
            "+--------------------+-----+--------------------+--------------------+--------------------+-----+\n",
            "|Great Mexican Foo...|  5.0|[great, mexican, ...|[great, mexican, ...|(1000,[0,1,3,19,2...|  0.0|\n",
            "|Keung's is one of...|  4.0|[keung, s, is, on...|[keung, one, fave...|(1000,[0,8,11,18,...|  1.0|\n",
            "|The food is great...|  4.0|[the, food, is, g...|[food, great, 5, ...|(1000,[0,1,3,5,7,...|  1.0|\n",
            "|Saw this restaura...|  4.0|[saw, this, resta...|[saw, restaurant,...|(1000,[1,3,9,10,1...|  1.0|\n",
            "|Delicious rotisse...|  5.0|[delicious, rotis...|[delicious, rotis...|(1000,[8,11,36,44...|  0.0|\n",
            "|If your looking f...|  3.0|[if, your, lookin...|[looking, somethi...|(1000,[3,10,23,79...|  3.0|\n",
            "|I like this place...|  3.0|[i, like, this, p...|[like, place, alt...|(1000,[0,1,2,4,6,...|  3.0|\n",
            "|Living in Hunters...|  5.0|[living, in, hunt...|[living, huntersv...|(1000,[0,1,2,3,6,...|  0.0|\n",
            "|A local favorite ...|  4.0|[a, local, favori...|[local, favorite,...|(1000,[1,2,5,6,7,...|  1.0|\n",
            "|Incredibly good c...|  4.0|[incredibly, good...|[incredibly, good...|(1000,[2,8,10,19,...|  1.0|\n",
            "+--------------------+-----+--------------------+--------------------+--------------------+-----+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a83936a3"
      },
      "source": [
        "lr = LogisticRegression(labelCol=\"stars\", featuresCol=\"features\",maxIter=15, regParam=0.1)\n",
        "lrModel = lr.fit(trainingData)\n",
        "predictions = lrModel.transform(testData)"
      ],
      "id": "a83936a3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfcc1199",
        "outputId": "4d7c56ea-c9e7-4162-ef77-7860e1949cf9"
      },
      "source": [
        "evaluator = MulticlassClassificationEvaluator(predictionCol='prediction',labelCol=\"stars\",metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(accuracy)"
      ],
      "id": "cfcc1199",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5871770599898263\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ff3e2cc"
      },
      "source": [
        ""
      ],
      "id": "0ff3e2cc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9551c07a"
      },
      "source": [
        "nb = NaiveBayes(modelType=\"multinomial\",labelCol=\"stars\", featuresCol=\"features\")\n",
        "nbModel = nb.fit(trainingData)\n",
        "nb_predictions = nbModel.transform(testData)\n"
      ],
      "id": "9551c07a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d46e63a3",
        "outputId": "a824b461-1008-42b6-fed7-cb266a03f1d6"
      },
      "source": [
        "## Evaluating the model\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"stars\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "nb_accuracy = evaluator.evaluate(nb_predictions)\n",
        "print(\"Accuracy of NaiveBayes is = %g\"% (nb_accuracy))"
      ],
      "id": "d46e63a3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of NaiveBayes is = 0.60583\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "699355a5"
      },
      "source": [
        "# nbModel.save('gs://project-final/modelpath/')"
      ],
      "id": "699355a5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8e868315"
      },
      "source": [
        "dt = DecisionTreeClassifier(featuresCol = 'features', labelCol = 'stars', maxDepth = 10)\n",
        "dtModel = dt.fit(trainingData)\n",
        "dtPreds = dtModel.transform(testData)\n"
      ],
      "id": "8e868315",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2c10a1db",
        "outputId": "3b9a8344-108a-4020-f3bc-df062ef154ed"
      },
      "source": [
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"stars\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "dt_accuracy = evaluator.evaluate(dtPreds)\n",
        "print(\"Accuracy of Decision Trees is = %g\"% (dt_accuracy))"
      ],
      "id": "2c10a1db",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of Decision Trees is = 0.523514\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9f1df7b4"
      },
      "source": [
        ""
      ],
      "id": "9f1df7b4",
      "execution_count": null,
      "outputs": []
    }
  ]
}